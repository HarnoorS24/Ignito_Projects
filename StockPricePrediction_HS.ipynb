{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67326f9",
   "metadata": {},
   "source": [
    "# Stock Price Prediction\n",
    "\n",
    "## Main Goals\n",
    "- Predict the future price of a stock using its historical data.\n",
    "- Create lag features, rolling averages, and moving window statistics to capture time-series patterns\n",
    "- Apply feature scaling (standardization) to prepare data for modeling.\n",
    "\n",
    "### Context\n",
    "Financial markets are a cornerstone of the global economy, and predicting stock price movements is a notoriously challenging and highly sought-after goal for investors and financial institutions. Stock prices are not random; they are a form of time-series data where future values are dependent on past values, trends, and volatility. In the field of data science, time-series analysis provides a framework for tackling this problem. By engineering features that capture historical patterns, such as lag features (past prices) and rolling statistics (moving averages), we can transform a sequence of prices into a format suitable for machine learning. This project leverages historical price data for the S&P 500 ETF (SPY) to build a forecasting model, providing a hands-on introduction to time-series feature engineering and prediction.\n",
    "\n",
    "## 1. Loading in the Data\n",
    "For this project, we will use the yfinance Python library to programmatically download historical stock price data for the S&P 500 ETF (ticker: SPY). Instead of manually downloading a file, we will write a short script to fetch this data and save it locally as spy_data.csv. his is a common and reproducible method in data science. If you haven't installed the library, you can do so by running pip install yfinance in your terminal. This tool allows us to pull clean, up-to-date data directly from Yahoo Finance.\n",
    "\n",
    "We will write a short script to download the complete historical data for the S&P 500 ETF (ticker: SPY) and load it directly into a pandas DataFrame. This requires us to import both the yfinance and pandas libraries at the start of our notebook. We'll also take the liberty of saving this data to a csv so as to not have to download the data each time we need to run the code. The following code will fetch the data and prepare it for our use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8bf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "#Get the data for the S&P500. \n",
    "#It uses the symbol 'SPY', which is the short code for the S&P 500 ETF.\n",
    "#ticker is short for ticker symbol, which is a unique identifier for a stock.\n",
    "ticker_data = yf.Ticker('SPY')\n",
    "\n",
    "#Get the historical prices\n",
    "#We'll get all available data from the start date until today.\n",
    "#period=\"max\" gets all the data.\n",
    "df = ticker_data.history(period=\"max\")\n",
    "\n",
    "#This saves the downloaded data locally, so you don't have to re-download\n",
    "#it every time you run your script.\n",
    "#file_path = 'spy_data.csv'\n",
    "#df.to_csv(file_path)\n",
    "\n",
    "#df = pd.read_csv('spy_data.csv', index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04edf72f",
   "metadata": {},
   "source": [
    "Once the data is loaded into the spy_df DataFrame, we will display the first few rows to ensure it loaded correctly and to inspect the data's structure. It's important to understand what each column provided by the data source represents, such as Open, High, Low, and Close, which we will use as the basis for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3dbdca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Capital Gains</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-01-29 00:00:00-05:00</th>\n",
       "      <td>24.397778</td>\n",
       "      <td>24.397778</td>\n",
       "      <td>24.276396</td>\n",
       "      <td>24.380438</td>\n",
       "      <td>1003200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-01 00:00:00-05:00</th>\n",
       "      <td>24.397784</td>\n",
       "      <td>24.553846</td>\n",
       "      <td>24.397784</td>\n",
       "      <td>24.553846</td>\n",
       "      <td>480500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-02 00:00:00-05:00</th>\n",
       "      <td>24.536512</td>\n",
       "      <td>24.623213</td>\n",
       "      <td>24.484491</td>\n",
       "      <td>24.605873</td>\n",
       "      <td>201300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-03 00:00:00-05:00</th>\n",
       "      <td>24.640549</td>\n",
       "      <td>24.883313</td>\n",
       "      <td>24.623208</td>\n",
       "      <td>24.865973</td>\n",
       "      <td>529400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-04 00:00:00-05:00</th>\n",
       "      <td>24.952661</td>\n",
       "      <td>25.022022</td>\n",
       "      <td>24.675216</td>\n",
       "      <td>24.970001</td>\n",
       "      <td>531500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-24 00:00:00-04:00</th>\n",
       "      <td>604.330017</td>\n",
       "      <td>607.849976</td>\n",
       "      <td>603.409973</td>\n",
       "      <td>606.780029</td>\n",
       "      <td>67735300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-25 00:00:00-04:00</th>\n",
       "      <td>607.909973</td>\n",
       "      <td>608.609985</td>\n",
       "      <td>605.539978</td>\n",
       "      <td>607.119995</td>\n",
       "      <td>62114800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-26 00:00:00-04:00</th>\n",
       "      <td>608.989990</td>\n",
       "      <td>612.309998</td>\n",
       "      <td>608.369995</td>\n",
       "      <td>611.869995</td>\n",
       "      <td>78548400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-27 00:00:00-04:00</th>\n",
       "      <td>612.880005</td>\n",
       "      <td>616.390015</td>\n",
       "      <td>610.830017</td>\n",
       "      <td>614.909973</td>\n",
       "      <td>86258400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30 00:00:00-04:00</th>\n",
       "      <td>617.380005</td>\n",
       "      <td>619.219971</td>\n",
       "      <td>615.039978</td>\n",
       "      <td>617.849976</td>\n",
       "      <td>92502500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8160 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "1993-01-29 00:00:00-05:00   24.397778   24.397778   24.276396   24.380438   \n",
       "1993-02-01 00:00:00-05:00   24.397784   24.553846   24.397784   24.553846   \n",
       "1993-02-02 00:00:00-05:00   24.536512   24.623213   24.484491   24.605873   \n",
       "1993-02-03 00:00:00-05:00   24.640549   24.883313   24.623208   24.865973   \n",
       "1993-02-04 00:00:00-05:00   24.952661   25.022022   24.675216   24.970001   \n",
       "...                               ...         ...         ...         ...   \n",
       "2025-06-24 00:00:00-04:00  604.330017  607.849976  603.409973  606.780029   \n",
       "2025-06-25 00:00:00-04:00  607.909973  608.609985  605.539978  607.119995   \n",
       "2025-06-26 00:00:00-04:00  608.989990  612.309998  608.369995  611.869995   \n",
       "2025-06-27 00:00:00-04:00  612.880005  616.390015  610.830017  614.909973   \n",
       "2025-06-30 00:00:00-04:00  617.380005  619.219971  615.039978  617.849976   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  Capital Gains  \n",
       "Date                                                                         \n",
       "1993-01-29 00:00:00-05:00   1003200        0.0           0.0            0.0  \n",
       "1993-02-01 00:00:00-05:00    480500        0.0           0.0            0.0  \n",
       "1993-02-02 00:00:00-05:00    201300        0.0           0.0            0.0  \n",
       "1993-02-03 00:00:00-05:00    529400        0.0           0.0            0.0  \n",
       "1993-02-04 00:00:00-05:00    531500        0.0           0.0            0.0  \n",
       "...                             ...        ...           ...            ...  \n",
       "2025-06-24 00:00:00-04:00  67735300        0.0           0.0            0.0  \n",
       "2025-06-25 00:00:00-04:00  62114800        0.0           0.0            0.0  \n",
       "2025-06-26 00:00:00-04:00  78548400        0.0           0.0            0.0  \n",
       "2025-06-27 00:00:00-04:00  86258400        0.0           0.0            0.0  \n",
       "2025-06-30 00:00:00-04:00  92502500        0.0           0.0            0.0  \n",
       "\n",
       "[8160 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display the data\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb455b",
   "metadata": {},
   "source": [
    "Here we can see that we were able to import a lot of important data from the yfinance library. We can see we have the price fluctuations throughout the day (through open, high, low, and close), the number of shares in the S&P 500 shared that day (volume), as well as additional information, that is seemingly empty right now. While it doesn't seem like we have enough information to create our models with, please note that stock prices like these tend to have momentum from the previous day(s), and there are still patterns that we can use to predict the upcoming days.\n",
    "\n",
    "## 2. Preprocessing\n",
    "\n",
    "Having viewed our data, it's time to start cleaning up our data, and engineer features that will help whatever model we use predict our target. For now, let's start off by cleaning up our data a bit.\n",
    "\n",
    "### Handling Missing Values. \n",
    "As with most projects, we can start by searching for null values, as well as filtering out data that may not be useful to us. Using pandas functions, let's see which features have null entires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1630f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open             0\n",
      "High             0\n",
      "Low              0\n",
      "Close            0\n",
      "Volume           0\n",
      "Dividends        0\n",
      "Stock Splits     0\n",
      "Capital Gains    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cfa6d",
   "metadata": {},
   "source": [
    "While we fortunately do not have to deal with any null data, we can remember from earlier that our Dividends, Stock Splits, and Capital Gains features were seemingly empty. Let's double check and make sure there are values in these features that aren't just 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c77a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dividends: 103.96099999999998\n",
      "Total Stock Splits: 0.0\n",
      "Total Capital Gains: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Check if there are any values in the Dividends, Stock Splits, and Capital Gains features\n",
    "print(\"Total Dividends:\", df['Dividends'].sum())\n",
    "print(\"Total Stock Splits:\", df['Stock Splits'].sum())\n",
    "print(\"Total Capital Gains:\", df['Capital Gains'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09fc19",
   "metadata": {},
   "source": [
    "We can see here that we have no stock splits or capital gains, so we know we can drop these features. Before doing so, let's check how many rows actually contain any kind of information for the dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea5aa0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You can also just filter:\n",
    "print((df['Dividends'] > 0).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38360eff",
   "metadata": {},
   "source": [
    "We see that we only have 131 rows with dividends out of 8159 rows. While it's clear that we want to drop the Stock Splits and Capital Gains features, you might be divided on whether to drop the Dividends feature. However, due to it being sparse in the dataset and potentially being a form of data leakage (as the closing price tends to drop on days dividends are sent out.), we'll go ahead and remove this feature alongside the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051e7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the Dividends, Stock Splits, and Capital Gains columns\n",
    "df = df.drop(columns=['Dividends', 'Stock Splits', 'Capital Gains'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b106a",
   "metadata": {},
   "source": [
    "### Defining our Target\n",
    "\n",
    "The next thing we can do is to construct the target variable that our model will learn to predict. While the dataset provides multiple prices for each day (Open, High, Low, Close), we must select a single, consistent value to serve as our prediction goal. For this purpose, we will use the Close price, as it is the standard benchmark that reflects the market's final consensus on the stock's value after a full day of trading. To frame this as a predictive task, we will create a new 'Target' column by shifting the Close price column backwards by one day. This operation effectively sets the target for any given row to be the actual closing price of the following trading day, establishing the direct relationship our model needs to learn. This will naturally result in a NaN value for the final row in our dataset, as its target price lies in the future, and this row will subsequently be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5379b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining our Target and dropping the last row with NaN value\n",
    "df['target'] = df['Close'].shift(-1)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588189e",
   "metadata": {},
   "source": [
    "### Handling the Date\n",
    "\n",
    "Another thing we have to take care of is the Date feature. As of right now, it's likely stored as a string. While in a useful format, we can't make the most of it yet. Using pandas' .to_datetime function, we can store it as a special datetime object, which will help us with feature engineering later on, as well accessing rows based on the date. \n",
    "\n",
    "As such, we'll convert the function to datetime. Note that the Date isn't actually a feature right now, but the dataframe's index. This means we'll have to augument the index as opposed to a 'Date' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f238395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8159 entries, 1993-01-29 05:00:00+00:00 to 2025-06-27 04:00:00+00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Open    8159 non-null   float64\n",
      " 1   High    8159 non-null   float64\n",
      " 2   Low     8159 non-null   float64\n",
      " 3   Close   8159 non-null   float64\n",
      " 4   Volume  8159 non-null   int64  \n",
      " 5   target  8159 non-null   float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 446.2 KB\n"
     ]
    }
   ],
   "source": [
    "#Convert the 'Date', or index from a string into a datetime object.\n",
    "#Pandas is smart enough to understand this specific format without any extra help.\n",
    "#utc=True ensures that the datetime is in UTC format.\n",
    "#This is useful for consistency, especially if you're working with data from different time zones.\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "\n",
    "#Let's verify the result. The Data type of the index should now be 'datetime'.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e97bd2",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "As we move into the final stage of our preprocessing for now, we will focus on feature engineering. This is the process of creating new, predictive features from our existing data, which is absolutely essential for any time-series forecasting model. Our goal is to transform our single column of historical prices into a rich dataset where each row contains a wealth of context that our model can use to make a prediction. To do this, we will craft features that describe the stock's recent behavior, including its momentum and volatility, giving our model the historical perspective it needs.\n",
    "\n",
    "Specifically, we will engineer two main types of features. First, we will create lag features, which are simply the price or return values from previous days (such as the price from 1 day ago, 3 days ago, etc.). This directly feeds the model information about recent price action. Second, we will generate rolling window statistics, such as moving averages and standard deviations, over various periods (like 5, 30, and 200 days). A moving average helps the model identify the underlying trend, while a rolling standard deviation provides a crucial measure of recent volatility. \n",
    "\n",
    "We will accomplish this using powerful pandas functions like `.shift()` to create the lags and `.rolling()` to compute the window-based statistics, effectively turning our time-series sequence into a structured dataset ready for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a73bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's often better to use returns (percentage change) for features, as they are more stationary.\n",
    "#Let's create a new column for daily returns, being the percentage change of the 'Close' price.\n",
    "df['daily_return'] = df['Close'].pct_change()\n",
    "\n",
    "#Lag Features (based on daily returns)\n",
    "#We shift the daily_return to use past information to predict the future.\n",
    "for lag in [1, 2, 3, 5, 10]: #amount of days\n",
    "    df[f'lag_return_{lag}'] = df['daily_return'].shift(lag)\n",
    "\n",
    "#Rolling Window Features\n",
    "#We calculate rolling statistics on the 'Close' price.\n",
    "#The .shift(1) ensures we are not using the current day's price to create features for itself (lookahead bias).\n",
    "for window in [5, 10, 30, 90, 200]: # amount of days\n",
    "    # Rolling Mean (Moving Average)\n",
    "    df[f'moving_avg_{window}'] = df['Close'].rolling(window=window).mean().shift(1)\n",
    "    \n",
    "    # Rolling Standard Deviation (Volatility)\n",
    "    df[f'volatility_{window}'] = df['Close'].rolling(window=window).std().shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323f9ef",
   "metadata": {},
   "source": [
    "While we're at it, we also want to go ahead and take advantage of our other features and create features off of those.  We can calculate the range of prices by subtracting high and low for one day, and we can calculate momentum by subtracting the opening prices from the closing prices. We'll also using the .rolling() function to get the average volume over thirty days, and turn that into a feature as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca51287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after creating features and dropping NaNs: (7959, 25)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#These features capture intra-day dynamics and market activity.\n",
    "#We shift them by 1 to avoid lookahead bias (we don't know the range until the end of the day).\n",
    "#Intra-day range\n",
    "df['intra_day_range'] = (df['High'] - df['Low']).shift(1)\n",
    "\n",
    "#Intra-day momentum\n",
    "df['intra_day_momentum'] = (df['Close'] - df['Open']).shift(1)\n",
    "\n",
    "#Rolling average of volume\n",
    "df['moving_avg_volume_30'] = df['Volume'].rolling(window=30).mean().shift(1)\n",
    "\n",
    "#The target for the last day is NaN, and the first N rows (N=largest window)\n",
    "#will have NaNs from the rolling features. We must drop them.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Display the DataFrame shape after creating features and dropping NaNs\n",
    "print(f\"DataFrame shape after creating features and dropping NaNs: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5d663",
   "metadata": {},
   "source": [
    "With that, we have engineered all the features we need, we're ready to move on to our test train split\n",
    "\n",
    "## 4. Chronological Test Train Split\n",
    "While we would typically import the test_train_split function from Sklearn, things aren't as simple this time. We cannot use the standard train_test_split function because it shuffles the data randomly. In forecasting, that would be like using information from the future to predict the past, which is impossible in the real world.\n",
    "\n",
    "Instead, we must split our data chronologically. We will pick a specific date and use all the data before that date for training our model, and all the data after that date for testing it. This perfectly simulates a real-world scenario where you train a model on historical data and then use it to make predictions on new, unseen data.\n",
    "\n",
    "Just as usual however, we'll start with separting our features from our target, and then try to create a 80%-20% split so that we have 80% of our data used for training, and 20% used for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eea8a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the index of the split date at around the 80% mark\n",
    "split_index = int(len(df) * 0.8)\n",
    "\n",
    "#Get the actual split date\n",
    "split_date = df.index[split_index]\n",
    "\n",
    "#Separate features and target\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "#Create a chronological split\n",
    "X_train = X[X.index < split_date]\n",
    "X_test = X[X.index >= split_date]\n",
    "y_train = y[y.index < split_date]\n",
    "y_test = y[y.index >= split_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401be62",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling \n",
    "\n",
    "Although we had split our data differently than normal, it's all we needed in order to move on to scaling the features. This is because we can still scale the data based on the training data, and then tranform both training and testing data to avoid data leakage. We scale the data so that larger values or features with larger values don't get prioritized by the model. For example, the values in the Volume features are simply much larger by default, so without feature scaling, they'll be treated with more importance in the model.\n",
    "\n",
    "As such, we'll import the standard scaler from Sklearn, fit it on the training data, and then transform both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f986bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit the scaler on the training data and transform both train and test sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85470c8b",
   "metadata": {},
   "source": [
    "## 6. Building and Training our Model\n",
    "\n",
    "With our preprocessing complete, we can finally move on to building our model. For this project, we'll be using a linear regression. Being quick, easy to interpret, and is well suited to predicting continous values such as the prices in the stock market. \n",
    "\n",
    "As such, we'll import the linear regression module from sklearn, and fit it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c2e3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the linear regression module from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3f0c6",
   "metadata": {},
   "source": [
    "## 7. Evaluating our Model \n",
    "\n",
    "With our model trained on our training data, it's time to evaluate it. We'll be importing metrics of success from Sklearn and analyzing the results from there. These metrics are\n",
    "\n",
    "- Root Mean Squared Error (RMSE) â€“ Measures how far, on average, the model's predictions are from the true values. Heavily penalizes larger errors, and is useful when large mistakes are extra costly.\n",
    "\n",
    "- Mean Absolute Error (MAE) â€“ Averages all absolute differences between prediction and reality. Easy to interpret and less sensitive to outliers. The lower, the better.\n",
    "\n",
    "- RÂ² Score (Coefficient of Determination) â€“ Tells us how much of the variance in stock prices is explained by our model. The closer to 1, the better.\n",
    "\n",
    "Let's go ahead with our evaulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6451419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4.776039915484373\n",
      "R^2 Score: 0.9977126573360986\n",
      "Mean Absolute Error: 3.23980162110866\n"
     ]
    }
   ],
   "source": [
    "#Import metrics for evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "#Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "#Display the evaluation metrics\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aacc85",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Letâ€™s take a closer look at how our linear regression model performed in predicting stock prices. Unlike more complex ensemble approaches or models that rely on multiple transformations or feature interactions, we opted for a straightforward linear regression model. This choice was guided by the simplicity of our dataset and the goal of building an interpretable baseline for stock price forecasting.\n",
    "\n",
    "The results suggest that our model performed remarkably well. We achieved a Root Mean Squared Error (RMSE) of approximately $4.78, which means that, on average, our predictions differ from the actual stock prices by just under five dollars. The Mean Absolute Error (MAE) came in at about $3.24, providing a measure of the typical absolute error between predicted and actual values without disproportionately penalizing larger deviations. Together, these two metrics give us confidence that our model's predictions are not only consistent but reasonably accurate.\n",
    "\n",
    "Most notably, our model achieved an RÂ² score of 0.9977, indicating that it explains over 99.7% of the variation in stock prices within our dataset. This is an exceptionally strong result for a linear model, and it suggests that the linear relationships captured by our features are highly predictive of the target variable. While RÂ² is not the only measure of success, such a high value indicates that very little variance remains unexplained by our model.\n",
    "\n",
    "Even though we only used a single model and kept the architecture simple, the results speak for themselves. The low error values and high RÂ² score show that linear regression, when paired with relevant and clean features, can still offer powerful predictive capabilities. It's a strong reminder that in many cases, simpler models can be both effective and interpretable, a valuable combination in both academic and practical settings.\n",
    "\n",
    "### Conclusion\n",
    "Throughout this project, we carefully guided the SPY dataset through every stage of the time-series forecasting pipeline, from programmatic data acquisition to specialized feature engineering and the final evaluation of our regression model. By handling time-aware data, creating lag and rolling window features to capture trends and volatility, and implementing a leak-proof chronological split, we prepared our data to reveal the patterns that drive short-term price movements.\n",
    "\n",
    "But the value of this process goes beyond predicting stock prices alone. Building and refining time-series models teaches us how to find predictive signals in sequential data, transforming a simple list of prices into insights that can inform decisions in fields like finance, economics, and inventory management. The methods we used here, such as creating stationary features from non-stationary data and correctly splitting data chronologically, are essential not only for coursework but for tackling real-world forecasting challenges where accuracy and robust methodology matter.\n",
    "\n",
    "By practicing data preparation, thoughtful time-series feature engineering, and a rigorous evaluation of our model, we have built a solid foundation for tackling future forecasting tasks. These same skills apply across nearly every area of data science, whether we are forecasting sales, predicting patient vitals, or modeling climate data. For now, good work, and give yourself a pat on the back."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
